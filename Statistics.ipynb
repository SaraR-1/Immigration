{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import folium\n",
    "import branca.colormap as cm\n",
    "import os\n",
    "import json\n",
    "import plot_function\n",
    "import map_visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resident_foreigners_norm = pd.read_table(\"Data_final/resident_foreigners_norm.csv\", sep = \"\\t\")\n",
    "\n",
    "resident_norm = pd.read_table(\"Data_final/resident_norm.csv\", sep = \"\\t\")\n",
    "\n",
    "provincia_regione = pd.read_table(\"Data_final/regioni.csv\", sep = \"\\t\")\n",
    "# to have a more readible db\n",
    "provincia_regione[\"Regione\"] = provincia_regione[\"Regione\"].replace({\"Provincia Autonoma Bolzano / Bozen\": \"Provincia Autonoma di Bolzano\", \n",
    "                                                                    \"Provincia Autonoma Trento\": \"Provincia Autonoma di Trento\", \n",
    "                                                                    \"Valle d'Aosta / Vallée d'Aoste\": \"Valle d'Aosta\"})\n",
    "\n",
    "regione_zona = pd.read_table(\"Data_final/territori.csv\", sep = \"\\t\")\n",
    "# to have a more readible db\n",
    "regione_zona[\"Regione\"] = regione_zona[\"Regione\"].replace({\"Provincia Autonoma Bolzano / Bozen\": \"Provincia Autonoma di Bolzano\", \n",
    "                                                                    \"Provincia Autonoma Trento\": \"Provincia Autonoma di Trento\", \n",
    "                                                                    \"Valle d'Aosta / Vallée d'Aoste\": \"Valle d'Aosta\"})\n",
    "geo_info = pd.read_table(\"Data_final/cepii_geo_info.csv\", sep = \"\\t\",)\n",
    "\n",
    "years = sorted(list(set(resident_foreigners_norm[\"Year\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region distribution - aggragation over the year\n",
    "regioni_aggr = {}\n",
    "\n",
    "for r in list(set(regione_zona[\"Regione\"])):\n",
    "    regioni_aggr[r] = sum([sum(resident_foreigners_norm[resident_foreigners_norm[\"Province\"] == i][\"Value\"].values) for i in provincia_regione[provincia_regione[\"Regione\"] == r][\"Provincia\"].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region distribution across the years I\n",
    "\n",
    "# Absolute values - foreigners\n",
    "regioni = {}\n",
    "\n",
    "for r in list(set(regione_zona[\"Regione\"])):\n",
    "    regioni[r] = {y: sum([sum(resident_foreigners_norm[(resident_foreigners_norm[\"Province\"] == i) \n",
    "                                                          & (resident_foreigners_norm[\"Year\"] == y)][\"Value\"].values) \n",
    "                             for i in provincia_regione[provincia_regione[\"Regione\"] == r][\"Provincia\"].values]) \n",
    "                  for y in years}\n",
    "\n",
    "# Absolute values - native\n",
    "regioni_native = {}\n",
    "for r in list(set(regione_zona[\"Regione\"])):\n",
    "    regioni_native[r] = {y: sum([sum(resident_norm[(resident_norm[\"Province\"] == i) \n",
    "                                                          & (resident_norm[\"Year\"] == y)][\"Value\"].values) \n",
    "                             for i in provincia_regione[provincia_regione[\"Regione\"] == r][\"Provincia\"].values]) \n",
    "                  for y in years}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region distribution across the years I\n",
    "\n",
    "# Growth\n",
    "regioni_growth = {}\n",
    "for r in regioni.keys():\n",
    "    regioni_growth[r] = {str(y+1)+\"-\"+str(y): regioni[r][y+1] - regioni[r][y] for y in years[:-1]}\n",
    "    \n",
    "# Relative values - divided by the previous year value\n",
    "regioni_prev_growth = {}\n",
    "for r in regioni.keys():\n",
    "    regioni_prev_growth[r] = {str(y+1)+\"-\"+str(y): 1.*(regioni[r][y+1] - regioni[r][y])/regioni[r][y] for y in years[:-1]}\n",
    "    \n",
    "    \n",
    "# Relative values - normalized by native population\n",
    "regioni_norm_native = {}\n",
    "for r in regioni.keys():\n",
    "    regioni_norm_native[r] = {y: 0 if regioni[r][y]==0 and regioni_native[r][y] == 0 else 1.*regioni[r][y]/regioni_native[r][y] for y in years}\n",
    "    \n",
    "# Growth - normalized by native population\n",
    "regioni_growth_norm_native = {}\n",
    "for r in regioni_norm_native.keys():\n",
    "    regioni_growth_norm_native[r] = {str(y+1)+\"-\"+str(y): regioni_norm_native[r][y+1] - regioni_norm_native[r][int(y)] for y in years[:-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the key \"y\" (year) and the values have to be a string to be written in the json --> transform it before the dump\n",
    "regioni_temp = {k1: dict([str(k2), str(v2)] for k2, v2 in v1.items()) for k1, v1 in regioni.items()}\n",
    "with open('Statistics/region_abs.json', 'w') as outfile:\n",
    "    json.dump(regioni_temp, outfile)\n",
    "    \n",
    "regioni_growth_temp = {k1: dict([k2, str(v2)] for k2, v2 in v1.items()) for k1, v1 in regioni_growth.items()}\n",
    "with open('Statistics/region_abs_growth.json', 'w') as outfile:\n",
    "    json.dump(regioni_growth_temp, outfile)\n",
    "    \n",
    "regioni_prev_growth_temp = {k1: dict([k2, str(v2)] for k2, v2 in v1.items()) for k1, v1 in regioni_prev_growth.items()}\n",
    "with open('Statistics/region_prev_growth.json', 'w') as outfile:\n",
    "    json.dump(regioni_prev_growth_temp, outfile)\n",
    "    \n",
    "regioni_norm_native_temp = {k1: dict([str(k2), str(v2)] for k2, v2 in v1.items()) for k1, v1 in regioni_norm_native.items()}\n",
    "with open('Statistics/region_native_norm.json', 'w') as outfile:\n",
    "    json.dump(regioni_norm_native_temp, outfile)\n",
    "\n",
    "regioni_growth_norm_native_temp = {k1: dict([k2, str(v2)] for k2, v2 in v1.items()) for k1, v1 in regioni_growth_norm_native.items()}\n",
    "with open('Statistics/region_native_norm_growth.json', 'w') as outfile:\n",
    "    json.dump(regioni_growth_norm_native_temp, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zone distribution across the years\n",
    "\n",
    "# Absolute values - foreigners\n",
    "zone = {}\n",
    "\n",
    "for z in list(set(regione_zona[\"Zona\"])):\n",
    "    temp = regione_zona[regione_zona[\"Zona\"] == z][\"Regione\"].values\n",
    "    zone[z] = {y: sum([regioni[t][y] for t in temp]) for y in years}\n",
    "    \n",
    "# Absolute values - native\n",
    "zone_native = {}\n",
    "for z in list(set(regione_zona[\"Zona\"])):\n",
    "    temp = regione_zona[regione_zona[\"Zona\"] == z][\"Regione\"].values\n",
    "    zone_native[z] = {y: sum([regioni_native[t][y] for t in temp]) for y in years}\n",
    "    \n",
    "# Growth\n",
    "zone_growth = {}\n",
    "for z in zone.keys():\n",
    "    #zone_growth[z] = [zone[z][2013]]+[zone[z][y+1] - zone[z][y] for y in years[:-1]]\n",
    "    zone_growth[z] = {str(y+1)+\"-\"+str(y): zone[z][y+1] - zone[z][y] for y in years[:-1]}\n",
    "    \n",
    "# Relative values - divided by the previous year value\n",
    "zone_prev_growth = {}\n",
    "for z in zone.keys():\n",
    "    zone_prev_growth[z] = {str(y+1)+\"-\"+str(y): 1.*(zone[z][y+1] - zone[z][y])/zone[z][y] for y in years[:-1]}\n",
    "    \n",
    "\n",
    "# Relative values - normalized by native population\n",
    "zone_norm_native = {}\n",
    "for z in zone.keys():\n",
    "    zone_norm_native[z] = {y: 0 if zone[z][y]==0 and zone_native[z][y] == 0 else 1.*zone[z][y]/zone_native[z][y] for y in years}\n",
    "    \n",
    "# Growth - normalized by native population\n",
    "zone_growth_norm_native = {}\n",
    "for z in zone_norm_native.keys():\n",
    "    zone_growth_norm_native[z] = {str(y+1)+\"-\"+str(y): zone_norm_native[z][y+1] - zone_norm_native[z][y] for y in years[:-1]}\n",
    "    \n",
    "# Growth - normalized by native population\n",
    "zone_growth_norm_native2 = {}\n",
    "for z in zone_norm_native.keys():\n",
    "    zone_growth_norm_native2[z] = {str(y+1)+\"-\"+str(y): 1.*(zone[z][y+1] - zone[z][y])/(zone_native[z][y+1] - zone_native[z][y]) for y in years[:-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the key \"y\" (year) and the values have to be a string to be written in the json --> transform it before the dump\n",
    "zone_temp = {k1: dict([str(k2), str(v2)] for k2, v2 in v1.items()) for k1, v1 in zone.items()}\n",
    "with open('Statistics/zone_abs.json', 'w') as outfile:\n",
    "    json.dump(zone_temp, outfile)\n",
    "    \n",
    "zone_growth_temp = {k1: dict([k2, str(v2)] for k2, v2 in v1.items()) for k1, v1 in zone_growth.items()}\n",
    "with open('Statistics/zone_abs_growth.json', 'w') as outfile:\n",
    "    json.dump(zone_growth_temp, outfile)\n",
    "    \n",
    "zone_prev_growth_temp = {k1: dict([k2, str(v2)] for k2, v2 in v1.items()) for k1, v1 in zone_prev_growth.items()}\n",
    "with open('Statistics/zone_prev_growth.json', 'w') as outfile:\n",
    "    json.dump(zone_prev_growth_temp, outfile)\n",
    "    \n",
    "zone_norm_native_temp = {k1: dict([str(k2), str(v2)] for k2, v2 in v1.items()) for k1, v1 in zone_norm_native.items()}\n",
    "with open('Statistics/zone_native_norm.json', 'w') as outfile:\n",
    "    json.dump(zone_norm_native_temp, outfile)\n",
    "\n",
    "zone_growth_norm_native_temp = {k1: dict([k2, str(v2)] for k2, v2 in v1.items()) for k1, v1 in zone_growth_norm_native.items()}\n",
    "with open('Statistics/zone_native_norm_growth.json', 'w') as outfile:\n",
    "    json.dump(zone_growth_norm_native_temp, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continent information stored in geo_info db\n",
    "# dictionary with structure: {continent: [list iso3 countries]}\n",
    "continent = {i: j.values for i, j in geo_info.groupby([\"continent\"])[\"iso3\"]}\n",
    "continent = {i: list(set(j)) for i, j in continent.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also store the dictionary containing the color - region/zone matchin\n",
    "color_region_list = [\"black\", \"grey\", \"lightgray\", \"firebrick\", \"red\", \n",
    "                     \"salmon\", \"chocolate\", \"saddlebrown\", \"peachpuff\", \n",
    "                     \"burlywood\", \"khaki\", \"gold\", \"greenyellow\", \n",
    "                     \"darkgreen\", \"g\", \"springgreen\", \"aquamarine\", \n",
    "                     \"cornflowerblue\", \"navy\", \"darkorchid\", \"orchid\"]\n",
    "\n",
    "color_region_dict = {r:c for r, c in zip(sorted(regioni.keys()), color_region_list)}\n",
    "\n",
    "color_zone_list = [\"red\", \"gold\", \"greenyellow\", \"cornflowerblue\",\"orchid\"]\n",
    "\n",
    "color_zone_dict = {z:c for z, c in zip(sorted(zone.keys()), color_zone_list)}\n",
    "color_continent_dict = {\"America\": \"greenyellow\", \"Pacific\": \"gold\", \"Europe\": \"red\", \n",
    "                        \"Asia\": \"cornflowerblue\", \"Africa\": \"orchid\"}\n",
    "\n",
    "with open('Statistics/color_region_dict.json', 'w') as outfile:\n",
    "    json.dump(color_region_dict, outfile)\n",
    "    \n",
    "with open('Statistics/color_zone_dict.json', 'w') as outfile:\n",
    "    json.dump(color_zone_dict, outfile)\n",
    "\n",
    "with open('Statistics/color_continent_dict.json', 'w') as outfile:\n",
    "    json.dump(color_continent_dict, outfile)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Costruire palette per ogni country in modo intelligente: \n",
    "- ogni continente è rappresentata dalla sfumatura del corrispondente colore in color_continent_dict\n",
    "'''\n",
    "color_country_dict = {}\n",
    "countries_list = []\n",
    "for i in continent.keys():\n",
    "    palette = sns.light_palette(color_continent_dict[i], len(continent[i]))\n",
    "    continent_stream = sorted(continent[i])\n",
    "    for c in continent_stream:\n",
    "        pos = continent_stream.index(c)\n",
    "        # string 'cause we can not dump an array\n",
    "        color_country_dict[c] = [str(c) for c in palette[pos]]\n",
    "        countries_list.append(c)\n",
    "\n",
    "with open('Statistics/color_country_dict.json', 'w') as outfile:\n",
    "    json.dump(color_country_dict, outfile) \n",
    "    \n",
    "# countries list in the right order order by continent\n",
    "with open('Statistics/countries_list.txt', 'wb') as fp:\n",
    "    pickle.dump(countries_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 53 colors palette\n",
    "Africa_palette_list = [\"black\", \"grey\", \"lightgray\", \"whitesmoke\", \"rosybrown\", \"lightcoral\", \"indianred\", \"brown\", \n",
    "                       \"maroon\", \"red\",\"mistyrose\", \"darksalmon\", \"coral\", \"lightsalmon\", \"sienna\", \"chocolate\", \n",
    "                       \"sandybrown\", \"peachpuff\", \"peru\", \"darkorange\", \"burlywood\", \"goldenrod\", \"gold\", \"khaki\", \n",
    "                       \"darkkhaki\", \"olive\", \"y\", \"olivedrab\", \"yellowgreen\", \"darkolivegreen\", \"chartreuse\", \n",
    "                       \"darkseagreen\", \"darkgreen\", \"green\", \"mediumseagreen\", \"springgreen\", \"turquoise\",\n",
    "                       \"paleturquoise\", \"cyan\", \"deepskyblue\", \"lightskyblue\", \"cornflowerblue\", \"royalblue\", \n",
    "                       \"midnightblue\", \"blue\", \"slateblue\", \"mediumpurple\", \"rebeccapurple\", \"indigo\", \"m\", \n",
    "                       \"fuchsia\", \"mediumvioletred\", \"palevioletred\"]\n",
    "Africa_palette = {cou: c for cou, c in zip(sorted(continent[\"Africa\"]), Africa_palette_list)}\n",
    "with open('Statistics/Africa_palette.json', 'w') as outfile:\n",
    "    json.dump(Africa_palette, outfile)\n",
    "\n",
    "# 49 colors palette\n",
    "Asia_palette_list = [\"black\", \"grey\", \"lightgray\", \"whitesmoke\", \"rosybrown\", \"lightcoral\", \"indianred\", \"brown\", \n",
    "                     \"maroon\", \"red\",\"mistyrose\",  \"coral\", \"lightsalmon\", \"sienna\", \"chocolate\", \"sandybrown\", \n",
    "                     \"peachpuff\", \"peru\", \"darkorange\", \"burlywood\", \"goldenrod\", \"gold\", \"khaki\", \"darkkhaki\",\n",
    "                     \"olive\", \"y\", \"olivedrab\", \"yellowgreen\", \"darkolivegreen\", \"chartreuse\", \"darkseagreen\", \n",
    "                     \"darkgreen\", \"green\", \"mediumseagreen\", \"turquoise\", \"paleturquoise\", \"cyan\", \"deepskyblue\", \n",
    "                     \"lightskyblue\", \"cornflowerblue\", \"midnightblue\", \"blue\", \"mediumpurple\", \"rebeccapurple\", \n",
    "                     \"indigo\", \"m\", \"fuchsia\", \"mediumvioletred\", \"palevioletred\"]\n",
    "Asia_palette = {cou: c for cou, c in zip(sorted(continent[\"Asia\"]), Asia_palette_list)}\n",
    "with open('Statistics/Asia_palette.json', 'w') as outfile:\n",
    "    json.dump(Asia_palette, outfile)\n",
    "\n",
    "# 44 colors palette\n",
    "Europe_palette_list = [\"black\", \"grey\", \"lightgray\", \"whitesmoke\", \"rosybrown\", \"lightcoral\", \"indianred\", \"brown\", \n",
    "                       \"maroon\", \"red\", \"mistyrose\",  \"coral\", \"lightsalmon\", \"sienna\", \"chocolate\", \"sandybrown\", \n",
    "                       \"peachpuff\", \"peru\", \"burlywood\", \"goldenrod\", \"gold\", \"khaki\", \"y\", \"olivedrab\", \"yellowgreen\", \n",
    "                       \"darkolivegreen\", \"chartreuse\", \"darkseagreen\", \"darkgreen\", \"green\", \"mediumseagreen\", \n",
    "                       \"turquoise\", \"paleturquoise\", \"deepskyblue\", \"lightskyblue\", \"cornflowerblue\", \"midnightblue\", \n",
    "                       \"blue\", \"mediumpurple\", \"rebeccapurple\", \"m\", \"fuchsia\", \"mediumvioletred\", \"palevioletred\"]\n",
    "Europe_palette = {cou: c for cou, c in zip(sorted(continent[\"Europe\"]), Europe_palette_list)}\n",
    "with open('Statistics/Europe_palette.json', 'w') as outfile:\n",
    "    json.dump(Europe_palette, outfile)\n",
    "\n",
    "# 35 colors palette\n",
    "America_palette_list = [\"black\", \"grey\", \"lightgray\", \"whitesmoke\", \"lightcoral\", \"indianred\", \"brown\", \"maroon\", \"red\", \n",
    "                        \"coral\", \"lightsalmon\", \"sienna\", \"chocolate\", \"sandybrown\", \"peachpuff\", \"burlywood\", \n",
    "                        \"goldenrod\", \"gold\", \"khaki\", \"y\", \"olivedrab\", \"yellowgreen\", \"darkolivegreen\", \"green\", \n",
    "                        \"mediumseagreen\", \"turquoise\", \"paleturquoise\", \"deepskyblue\", \"lightskyblue\", \n",
    "                        \"cornflowerblue\", \"midnightblue\", \"blue\", \"mediumpurple\", \"m\", \"fuchsia\"]\n",
    "America_palette = {cou: c for cou, c in zip(sorted(continent[\"America\"]), America_palette_list)}\n",
    "with open('Statistics/America_palette.json', 'w') as outfile:\n",
    "    json.dump(America_palette, outfile)\n",
    "    \n",
    "# 14 colors palette\n",
    "Pacific_palette_list = [\"black\", \"grey\", \"lightgray\", \"indianred\", \"maroon\", \"lightsalmon\", \"gold\", \"yellowgreen\", \n",
    "                        \"green\", \"paleturquoise\", \"deepskyblue\", \"blue\", \"mediumpurple\", \"fuchsia\"]\n",
    "Pacific_palette = {cou: c for cou, c in zip(sorted(continent[\"Pacific\"]), Pacific_palette_list)}\n",
    "with open('Statistics/Pacific_palette.json', 'w') as outfile:\n",
    "    json.dump(Pacific_palette, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# italian distribution across sex\n",
    "gender_dict = defaultdict(list)\n",
    "gender_dict[\"male\"] = [sum(resident_foreigners_norm[(resident_foreigners_norm[\"Gender\"] == \"male\") \n",
    "                                       & (resident_foreigners_norm[\"Year\"] == y)][\"Value\"]) for y in years]\n",
    "gender_dict[\"female\"] = [sum(resident_foreigners_norm[(resident_foreigners_norm[\"Gender\"] == \"female\") \n",
    "                                       & (resident_foreigners_norm[\"Year\"] == y)][\"Value\"]) for y in years]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender comparison\n",
    "gender_temp = {k1: [str(i) for i in v1] for k1, v1 in gender_dict.items()}\n",
    "with open('Statistics/gender_distribution.json', 'w') as outfile:\n",
    "    json.dump(gender_temp, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Province by origin country\n",
    "temp = {i: sum(j.values) for i, j in resident_foreigners_norm.groupby([\"Province\", \"Year\", \"Country\"])[\"Value\"]}\n",
    "\n",
    "all_c = list(set(resident_foreigners_norm[\"Country\"]))\n",
    "all_p = list(set(resident_foreigners_norm[\"Province\"]))\n",
    "py_prov_country = {p: {c: [0 for y in years] for c in all_c} for p in all_p}\n",
    "\n",
    "for k, v in temp.items():\n",
    "    py_prov_country[k[0]][k[2]][years.index(k[1])] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "py_prov_country_temp = {k1: {k2:[str(i) for i in v2] for k2, v2 in v1.items()} for k1, v1 in py_prov_country.items()}\n",
    "with open('Statistics/py_prov_country.json', 'w') as outfile:\n",
    "    json.dump(py_prov_country_temp, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region aggregation\n",
    "all_r = list(set(provincia_regione[\"Regione\"]))\n",
    "py_region_country = {r: {c: [0 for y in years] for c in all_c} for r in all_r}\n",
    "\n",
    "for p, d in py_prov_country.items():\n",
    "    r = provincia_regione[provincia_regione[\"Provincia\"] == p][\"Regione\"].values[0]\n",
    "    for c, v in d.items():\n",
    "        py_region_country[r][c] = [i+j for i, j in zip(py_region_country[r][c], np.array(v))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_region_country_temp = {k1: {k2:[str(i) for i in v2] for k2, v2 in v1.items()} for k1, v1 in py_region_country.items()}\n",
    "with open('Statistics/py_region_country.json', 'w') as outfile:\n",
    "    json.dump(py_region_country_temp, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zone aggregation\n",
    "all_z = list(set(regione_zona[\"Zona\"]))\n",
    "py_zone_country = {z: {c: [0 for y in years] for c in all_c} for z in all_z}\n",
    "\n",
    "for r, d in py_region_country.items():\n",
    "    z = regione_zona[regione_zona[\"Regione\"] == r][\"Zona\"].values[0]\n",
    "    for c, v in d.items():\n",
    "        py_zone_country[z][c] = [i+j for i, j in zip(py_zone_country[z][c], np.array(v))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_zone_country_temp = {k1: {k2:[str(i) for i in v2] for k2, v2 in v1.items()} for k1, v1 in py_zone_country.items()}\n",
    "with open('Statistics/py_zone_country.json', 'w') as outfile:\n",
    "    json.dump(py_zone_country_temp, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Province by origin continent\n",
    "all_cont = list(continent.keys())\n",
    "py_prov_continent = {p: {c: [0 for y in years] for c in all_cont} for p in py_prov_country.keys()}\n",
    "\n",
    "for p, d in py_prov_country.items():\n",
    "    for c, v in d.items():\n",
    "        cont = next(k for k in continent.keys() if c in continent[k])\n",
    "        py_prov_continent[p][cont] = [i+j for i, j in zip(py_prov_continent[p][cont], np.array(v))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_prov_continent_temp = {k1: {k2:[str(i) for i in v2] for k2, v2 in v1.items()} for k1, v1 in py_prov_continent.items()}\n",
    "with open('Statistics/py_prov_continent.json', 'w') as outfile:\n",
    "    json.dump(py_prov_continent_temp, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region aggregation\n",
    "py_region_continent = {p: {c: [0 for y in years] for c in all_cont} for p in py_region_country.keys()}\n",
    "\n",
    "for p, d in py_region_country.items():\n",
    "    for c, v in d.items():\n",
    "        cont = next(k for k in continent.keys() if c in continent[k])\n",
    "        py_region_continent[p][cont] = [i+j for i, j in zip(py_region_continent[p][cont], np.array(v))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_region_continent_temp = {k1: {k2:[str(i) for i in v2] for k2, v2 in v1.items()} for k1, v1 in py_region_continent.items()}\n",
    "with open('Statistics/py_region_continent.json', 'w') as outfile:\n",
    "    json.dump(py_region_continent_temp, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zone aggregation\n",
    "py_zone_continent = {p: {c: [0 for y in years] for c in all_cont} for p in py_zone_country.keys()}\n",
    "\n",
    "for p, d in py_zone_country.items():\n",
    "    for c, v in d.items():\n",
    "        cont = next(k for k in continent.keys() if c in continent[k])\n",
    "        py_zone_continent[p][cont] = [i+j for i, j in zip(py_zone_continent[p][cont], np.array(v))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_zone_continent_temp = {k1: {k2:[str(i) for i in v2] for k2, v2 in v1.items()} for k1, v1 in py_zone_continent.items()}\n",
    "with open('Statistics/py_zone_continent.json', 'w') as outfile:\n",
    "    json.dump(py_zone_continent_temp, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 countries for each continent (top 10 as aggregate values on the 2003-2017 period)\n",
    "# Province aggregation\n",
    "\n",
    "py_prov_top10_countrie_cont = {p: {} for p in all_p}\n",
    "py_prov_top5_countrie_cont = {p: {} for p in all_p}\n",
    "\n",
    "for p in py_prov_country.keys():\n",
    "    for cont in continent.keys():\n",
    "        cont_countries = continent[cont]\n",
    "        temp = sorted([(sum(py_prov_country[p][i]), i) for i in cont_countries])\n",
    "        temp10 = temp[-10:]\n",
    "        temp5 = temp[-5:]\n",
    "        temp10_top_idx = [i[1] for i in temp10]\n",
    "        temp5_top_idx = [i[1] for i in temp5]\n",
    "        py_prov_top10_countrie_cont[p].update({i: py_prov_country[p][i] for i in temp10_top_idx})\n",
    "        py_prov_top5_countrie_cont[p].update({i: py_prov_country[p][i] for i in temp5_top_idx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_prov_top10_countrie_cont_temp = {k1: {k2:[str(i) for i in v2] for k2, v2 in v1.items()} for k1, v1 in py_prov_top10_countrie_cont.items()}\n",
    "with open('Statistics/py_prov_top10_countrie_cont.json', 'w') as outfile:\n",
    "    json.dump(py_prov_top10_countrie_cont_temp, outfile)\n",
    "    \n",
    "py_prov_top5_countrie_cont_temp = {k1: {k2:[str(i) for i in v2] for k2, v2 in v1.items()} for k1, v1 in py_prov_top5_countrie_cont.items()}\n",
    "with open('Statistics/py_prov_top5_countrie_cont.json', 'w') as outfile:\n",
    "    json.dump(py_prov_top5_countrie_cont_temp, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region aggregation\n",
    "\n",
    "py_region_top10_countrie_cont = {r: {} for r in all_r}\n",
    "py_region_top5_countrie_cont = {r: {} for r in all_r}\n",
    "\n",
    "for r in py_region_country.keys():\n",
    "    for cont in continent.keys():\n",
    "        cont_countries = continent[cont]\n",
    "        temp = sorted([(sum(py_region_country[r][i]), i) for i in cont_countries])\n",
    "        temp10 = temp[-10:]\n",
    "        temp10_top_idx = [i[1] for i in temp10]\n",
    "        py_region_top10_countrie_cont[r].update({i: py_region_country[r][i] for i in temp10_top_idx})\n",
    "        temp5 = temp[-5:]\n",
    "        temp5_top_idx = [i[1] for i in temp5]\n",
    "        py_region_top5_countrie_cont[r].update({i: py_region_country[r][i] for i in temp5_top_idx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_region_top10_countrie_cont_temp = {k1: {k2:[str(i) for i in v2] for k2, v2 in v1.items()} for k1, v1 in py_region_top10_countrie_cont.items()}\n",
    "with open('Statistics/py_region_top10_countrie_cont.json', 'w') as outfile:\n",
    "    json.dump(py_region_top10_countrie_cont_temp, outfile)\n",
    "    \n",
    "py_region_top5_countrie_cont_temp = {k1: {k2:[str(i) for i in v2] for k2, v2 in v1.items()} for k1, v1 in py_region_top5_countrie_cont.items()}\n",
    "with open('Statistics/py_region_top5_countrie_cont.json', 'w') as outfile:\n",
    "    json.dump(py_region_top5_countrie_cont_temp, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zone aggregation\n",
    "\n",
    "py_zone_top10_countrie_cont = {z: {} for z in all_z}\n",
    "py_zone_top5_countrie_cont = {z: {} for z in all_z}\n",
    "\n",
    "for z in py_zone_country.keys():\n",
    "    for cont in continent.keys():\n",
    "        cont_countries = continent[cont]\n",
    "        temp = sorted([(sum(py_zone_country[z][i]), i) for i in cont_countries])\n",
    "        temp10 = temp[-10:]\n",
    "        temp10_top_idx = [i[1] for i in temp10]\n",
    "        py_zone_top10_countrie_cont[z].update({i: py_zone_country[z][i] for i in temp10_top_idx})\n",
    "        temp5 = temp[-5:]\n",
    "        temp5_top_idx = [i[1] for i in temp5]\n",
    "        py_zone_top5_countrie_cont[z].update({i: py_zone_country[z][i] for i in temp5_top_idx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_zone_top10_countrie_cont_temp = {k1: {k2:[str(i) for i in v2] for k2, v2 in v1.items()} for k1, v1 in py_zone_top10_countrie_cont.items()}\n",
    "with open('Statistics/py_zone_top10_countrie_cont.json', 'w') as outfile:\n",
    "    json.dump(py_zone_top10_countrie_cont_temp, outfile)\n",
    "    \n",
    "py_zone_top5_countrie_cont_temp = {k1: {k2:[str(i) for i in v2] for k2, v2 in v1.items()} for k1, v1 in py_zone_top5_countrie_cont.items()}\n",
    "with open('Statistics/py_zone_top5_countrie_cont.json', 'w') as outfile:\n",
    "    json.dump(py_zone_top5_countrie_cont_temp, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countries distribution for each continent\n",
    "# Province aggregation\n",
    "\n",
    "py_prov_cont_countries = {cont: {p: {} for p in all_p} for cont in all_cont}\n",
    "\n",
    "for cont in all_cont:\n",
    "    cont_countries = continent[cont]\n",
    "    for p in all_p:\n",
    "        py_prov_cont_countries[cont][p].update({i: py_prov_country[p][i] for i in cont_countries})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cont in all_cont:    \n",
    "    temp = {k1: {k2:[str(i) for i in v2] for k2, v2 in v1.items()} \n",
    "                                        for k1, v1 in py_prov_cont_countries[cont].items()}\n",
    "    with open('Statistics/py_prov_'+cont+'_countries.json', 'w') as outfile:\n",
    "        json.dump(temp, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region aggregation\n",
    "\n",
    "py_region_cont_countries = {cont: {r: {} for r in all_r} for cont in all_cont}\n",
    "\n",
    "for cont in all_cont:\n",
    "    cont_countries = continent[cont]\n",
    "    for r in all_r:\n",
    "        py_region_cont_countries[cont][r].update({i: py_region_country[r][i] for i in cont_countries})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cont in all_cont:    \n",
    "    temp = {k1: {k2:[str(i) for i in v2] for k2, v2 in v1.items()} \n",
    "                                        for k1, v1 in py_region_cont_countries[cont].items()}\n",
    "    with open('Statistics/py_region_'+cont+'_countries.json', 'w') as outfile:\n",
    "        json.dump(temp, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zone aggregation\n",
    "\n",
    "py_zone_cont_countries = {cont: {z: {} for z in all_z} for cont in all_cont}\n",
    "\n",
    "for cont in all_cont:\n",
    "    cont_countries = continent[cont]\n",
    "    for z in all_z:\n",
    "        py_zone_cont_countries[cont][z].update({i: py_zone_country[z][i] for i in cont_countries})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cont in all_cont:    \n",
    "    temp = {k1: {k2:[str(i) for i in v2] for k2, v2 in v1.items()} \n",
    "                                        for k1, v1 in py_zone_cont_countries[cont].items()}\n",
    "    with open('Statistics/py_zone_'+cont+'_countries.json', 'w') as outfile:\n",
    "        json.dump(temp, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sorted(regioni.keys())\n",
    "for i in a:\n",
    "    j = list(regioni[i].values())\n",
    "    print(\"| %s | %s | %s | %s | %s | %s | %s | %s | %s | %s | \" %(i, j[0], j[1], j[2], j[3], j[4], j[5], j[6], j[7], j[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sorted(regioni.keys())\n",
    "for i in a:\n",
    "    j = list(regioni[i].values())\n",
    "    print(\"| %s | %s | %s | %s | %s | %s | %s |\" %(i, j[9], j[10], j[11], j[12], j[13], j[14]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
